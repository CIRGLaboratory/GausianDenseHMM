{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 07:41:21.057335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-18 07:41:21.057397: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /ziob/klaudia/miniconda3/envs/hmm/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import  pickle\n",
    "import joblib\n",
    "import optuna\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from eval_utils import *\n",
    "from models_gaussian import GaussianDenseHMM, HMMLoggingMonitor, DenseHMMLoggingMonitor\n",
    "from models_gaussian_A import GaussianDenseHMM as CoocHMM\n",
    "from hmmlearn import hmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "t = time.localtime()\n",
    "RESULT_DIR = f'gaussian_dense_hmm_benchmark/eval-cooc-{t.tm_year}-{t.tm_mon}-{t.tm_mday}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have examined the efficiency of co-occurence based learning methods for Gaussian HMM. This notebook contains a comparison of:\n",
    "\n",
    "- standard Gaussian Hidden Markov Model implementation,\n",
    "- co-occurrence based larning for Gaussian Hidden Markov Model,\n",
    "- EM learning for GaussianDenseHHMM,\n",
    "- co-occurrence based learning for GaussianDenseHMM.\n",
    "\n",
    "The dense representation was examined with fixed and tuned embedding length."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "n = 8\n",
    "s = 100\n",
    "T = 1000\n",
    "simple_model = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "l_fixed = True\n",
    "\n",
    "RESULT_DIR = f'gaussian_dense_hmm_benchmark/eval-cooc-{t.tm_year}-{t.tm_mon}-{17}'\n",
    "with open(f\"{RESULT_DIR}/optuna_cooc_s{s}_T{T}_n{n}_simple_model{simple_model}_l{l_fixed}.pkl\", \"rb\") as f:\n",
    "    study = joblib.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    cooc_lr_param  cooc_epochs_param          mean           std\n0        0.007055              95252 -1.029042e+08  4.989413e+07\n1        0.000372              22013 -1.258788e+08  8.937642e+07\n2        0.016005              14357 -6.724162e+07  1.405187e+07\n3        0.315334              94224 -8.523348e+07  6.216957e+07\n4        0.054786              15321 -8.100231e+07  1.229705e+07\n5        0.001338              61685 -1.059174e+08  5.560698e+07\n6        0.000292              54599 -6.600827e+07  9.538663e+06\n7        0.070272              71114 -7.066690e+07  3.602548e+07\n8        0.312263              43095 -7.776879e+07  1.773118e+07\n9        0.000237              26975 -8.915181e+07  4.766469e+07\n10       0.001001              39586 -7.212859e+07  2.600582e+07\n11       0.446506              99209 -1.182312e+08  7.659809e+07\n12       0.000111              50020 -7.327907e+07  1.724211e+07\n13       0.000775              73176 -9.530288e+07  2.544203e+07\n14       0.070398              91875 -1.056092e+08  5.346814e+07\n15       0.000594              71827 -8.024238e+07  2.248703e+07\n16       0.000192              17909 -7.972843e+07  3.615685e+07\n17       0.002948              38099 -8.165278e+07  4.503880e+07\n18       0.201781              50368 -2.739705e+08  5.020861e+08\n19       0.002612              31394 -9.500772e+07  3.092008e+07\n20       0.013903              36177 -7.955373e+07  5.931536e+07\n21       0.037838              96577 -8.763162e+07  1.914613e+07\n22       0.419299              29103 -1.902856e+08  3.039974e+08\n23       0.006044              68533 -8.209136e+07  3.512586e+07\n24       0.000963              89393 -9.296827e+07  3.328557e+07\n25       0.074828              53265 -6.755254e+07  3.986388e+07\n26       0.024116              93694 -9.855420e+07  3.681705e+07\n27       0.001513              37451 -9.688019e+07  6.498089e+07\n28       0.060725              94151 -5.013962e+07  3.025958e+07\n29       0.004612              50432 -9.595474e+07  4.684733e+07\n30       0.012826              94882 -8.017866e+07  2.309183e+07\n31       0.000971              14429 -7.977648e+07  4.249492e+07",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cooc_lr_param</th>\n      <th>cooc_epochs_param</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.007055</td>\n      <td>95252</td>\n      <td>-1.029042e+08</td>\n      <td>4.989413e+07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000372</td>\n      <td>22013</td>\n      <td>-1.258788e+08</td>\n      <td>8.937642e+07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.016005</td>\n      <td>14357</td>\n      <td>-6.724162e+07</td>\n      <td>1.405187e+07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.315334</td>\n      <td>94224</td>\n      <td>-8.523348e+07</td>\n      <td>6.216957e+07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.054786</td>\n      <td>15321</td>\n      <td>-8.100231e+07</td>\n      <td>1.229705e+07</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.001338</td>\n      <td>61685</td>\n      <td>-1.059174e+08</td>\n      <td>5.560698e+07</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000292</td>\n      <td>54599</td>\n      <td>-6.600827e+07</td>\n      <td>9.538663e+06</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.070272</td>\n      <td>71114</td>\n      <td>-7.066690e+07</td>\n      <td>3.602548e+07</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.312263</td>\n      <td>43095</td>\n      <td>-7.776879e+07</td>\n      <td>1.773118e+07</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000237</td>\n      <td>26975</td>\n      <td>-8.915181e+07</td>\n      <td>4.766469e+07</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.001001</td>\n      <td>39586</td>\n      <td>-7.212859e+07</td>\n      <td>2.600582e+07</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.446506</td>\n      <td>99209</td>\n      <td>-1.182312e+08</td>\n      <td>7.659809e+07</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.000111</td>\n      <td>50020</td>\n      <td>-7.327907e+07</td>\n      <td>1.724211e+07</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.000775</td>\n      <td>73176</td>\n      <td>-9.530288e+07</td>\n      <td>2.544203e+07</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.070398</td>\n      <td>91875</td>\n      <td>-1.056092e+08</td>\n      <td>5.346814e+07</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.000594</td>\n      <td>71827</td>\n      <td>-8.024238e+07</td>\n      <td>2.248703e+07</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.000192</td>\n      <td>17909</td>\n      <td>-7.972843e+07</td>\n      <td>3.615685e+07</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.002948</td>\n      <td>38099</td>\n      <td>-8.165278e+07</td>\n      <td>4.503880e+07</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.201781</td>\n      <td>50368</td>\n      <td>-2.739705e+08</td>\n      <td>5.020861e+08</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.002612</td>\n      <td>31394</td>\n      <td>-9.500772e+07</td>\n      <td>3.092008e+07</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.013903</td>\n      <td>36177</td>\n      <td>-7.955373e+07</td>\n      <td>5.931536e+07</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.037838</td>\n      <td>96577</td>\n      <td>-8.763162e+07</td>\n      <td>1.914613e+07</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.419299</td>\n      <td>29103</td>\n      <td>-1.902856e+08</td>\n      <td>3.039974e+08</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.006044</td>\n      <td>68533</td>\n      <td>-8.209136e+07</td>\n      <td>3.512586e+07</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.000963</td>\n      <td>89393</td>\n      <td>-9.296827e+07</td>\n      <td>3.328557e+07</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.074828</td>\n      <td>53265</td>\n      <td>-6.755254e+07</td>\n      <td>3.986388e+07</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.024116</td>\n      <td>93694</td>\n      <td>-9.855420e+07</td>\n      <td>3.681705e+07</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.001513</td>\n      <td>37451</td>\n      <td>-9.688019e+07</td>\n      <td>6.498089e+07</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.060725</td>\n      <td>94151</td>\n      <td>-5.013962e+07</td>\n      <td>3.025958e+07</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.004612</td>\n      <td>50432</td>\n      <td>-9.595474e+07</td>\n      <td>4.684733e+07</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.012826</td>\n      <td>94882</td>\n      <td>-8.017866e+07</td>\n      <td>2.309183e+07</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.000971</td>\n      <td>14429</td>\n      <td>-7.977648e+07</td>\n      <td>4.249492e+07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_res = pd.DataFrame([{**t.params, \"mean\": t.values[0], \"std\": t.values[1]} for t in study.trials])\n",
    "study_res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='mean', ylabel='std'>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=study_res, x=\"mean\", y=\"std\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cooc': {'cooc_lr_param': 0.060724553741338755,\n  'cooc_epochs_param': 94151,\n  'l_param': 3}}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = dict()\n",
    "best_params[\"cooc\"] = study_res.sort_values(\"mean\").iloc[-1, :2].to_dict()\n",
    "best_params[\"cooc\"]['cooc_epochs_param'] = int(best_params[\"cooc\"]['cooc_epochs_param'])\n",
    "best_params[\"cooc\"]['l_param'] = int(np.ceil(n / 3))\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "best_result = {}\n",
    "s, T, n, pi, A, mu, sigma, result, true_values, wandb_params, X_true, Y_true, lengths, _, em_scheduler = init_experiment((s, T, n), simple_model)\n",
    "nodes = np.concatenate([np.array([-np.infty, Y_true.min()]),\n",
    "                        (mu[1:] + mu[:-1]) / 2,\n",
    "                        np.array([Y_true.max(), np.infty])])\n",
    "m = nodes.shape[0] - 1\n",
    "\n",
    "models = dict(cooc=CoocHMM, dense=GaussianDenseHMM, dense_em=GaussianDenseHMM)\n",
    "monitors = dict(cooc=DenseHMMLoggingMonitor, dense=DenseHMMLoggingMonitor, dense_em=DenseHMMLoggingMonitor)\n",
    "algs = dict(cooc=\"cooc\", dense=\"cooc\", dense_em=\"em\")\n",
    "\n",
    "## Tune hyper-parameters\n",
    "l = np.ceil(n / 3) if l_fixed else None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "lengths = np.array(lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def _lengths_iterator(seqs, lengths):\n",
    "    n_seqs = len(lengths)\n",
    "    left, right = 0, 0\n",
    "\n",
    "    for i in range(len(lengths)):\n",
    "        right += lengths[i]\n",
    "        yield seqs[left:right]\n",
    "        left += lengths[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00249859, 0.00148065, 0.001301  , 0.0019025 , 0.0223617 ,\n        0.01847599, 0.00621811, 0.00385021, 0.00197173, 0.00464706],\n       [0.00142556, 0.00111826, 0.00083279, 0.00080289, 0.01395968,\n        0.00691197, 0.00475485, 0.00306707, 0.00149095, 0.0035148 ],\n       [0.00141132, 0.00092005, 0.00075448, 0.00091582, 0.01088627,\n        0.00754757, 0.00343824, 0.003244  , 0.00111296, 0.00261852],\n       [0.00347152, 0.00204357, 0.00171855, 0.00206684, 0.00791379,\n        0.00823772, 0.00249817, 0.01641233, 0.00107767, 0.00249278],\n       [0.00720713, 0.00492176, 0.00516803, 0.01962201, 0.03583207,\n        0.08725304, 0.02039976, 0.01771643, 0.01133188, 0.02831558],\n       [0.02833943, 0.01776422, 0.01368818, 0.00899939, 0.07953052,\n        0.03831641, 0.04410347, 0.0270325 , 0.00333408, 0.00391704],\n       [0.00562601, 0.00282684, 0.00263223, 0.00380143, 0.0371787 ,\n        0.03714907, 0.01453571, 0.00805659, 0.00186449, 0.00357255],\n       [0.0058116 , 0.0036961 , 0.00309292, 0.00462091, 0.01823715,\n        0.03216148, 0.00952942, 0.01239134, 0.0030052 , 0.00702746],\n       [0.0025749 , 0.00090423, 0.00106248, 0.00154279, 0.00429176,\n        0.00916458, 0.00356005, 0.00232213, 0.00136544, 0.00314822],\n       [0.00634147, 0.00220314, 0.00259857, 0.00365836, 0.00757605,\n        0.0198074 , 0.00820585, 0.00548099, 0.00338216, 0.00783074]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_cooc_prob(densehmm.means_.reshape(-1), densehmm.covars_.reshape(-1), nodes, A)[1:, 1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model building:   0%|                                     | 0/3 [00:00<?, ?it/s]\n",
      "Training cooc:   0%|                                     | 0/10 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:zrciuhfg) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.052 MB of 0.052 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cc4a17ef10d46a3aa11586c48872f51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>time</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>total_log_prob</td><td>▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>time</td><td>29.94814</td></tr><tr><td>total_log_prob</td><td>-292834.6472</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">HMMlearn</strong>: <a href=\"https://wandb.ai/cirglaboratory/gaussian-dense-hmm/runs/zrciuhfg\" target=\"_blank\">https://wandb.ai/cirglaboratory/gaussian-dense-hmm/runs/zrciuhfg</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20220818_080026-zrciuhfg/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:zrciuhfg). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.13.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.21"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/ziob/klaudia/recommender_system/src/models/gaussian_dense_hmm/dense-hmm/code_dense_hmm/wandb/run-20220818_080204-3cpev6g4</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/cirglaboratory/gaussian-dense-hmm/runs/3cpev6g4\" target=\"_blank\">name-l=3-lr=0.060724553741338755-epochs=94151</a></strong> to <a href=\"https://wandb.ai/cirglaboratory/gaussian-dense-hmm\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 08:02:29.424134: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-18 08:02:29.424212: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-18 08:02:29.424257: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cymestmp): /proc/driver/nvidia/version does not exist\n",
      "2022-08-18 08:02:29.443902: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-18 08:02:29.506086: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "         1   -64778887.3333             +nan\n",
      "         2   -62186466.1983    +2592421.1350\n",
      "         3   -59844541.9977    +2341924.2006\n",
      "         4   -57845758.8592    +1998783.1385\n",
      "         5   -56068602.5980    +1777156.2612\n",
      "         6   -54438200.8265    +1630401.7715\n",
      "         7   -52992396.5112    +1445804.3153\n",
      "         8   -51721635.6527    +1270760.8585\n",
      "         9   -50525356.7573    +1196278.8954\n",
      "        10   -49342552.8556    +1182803.9017\n",
      "        11   -48207222.3554    +1135330.5002\n",
      "        12   -47138918.8646    +1068303.4909\n",
      "        13   -46081229.2443    +1057689.6203\n",
      "        14   -45000906.1459    +1080323.0984\n",
      "        15   -43946941.8357    +1053964.3102\n",
      "        16   -42950968.5382     +995973.2975\n",
      "        17   -41967817.8521     +983150.6862\n",
      "        18   -40971023.6324     +996794.2197\n",
      "        19   -40008252.0911     +962771.5413\n",
      "        20   -39108455.5614     +899796.5297\n",
      "        21   -38230220.8435     +878234.7178\n",
      "        22   -37349877.6412     +880343.2023\n",
      "        23   -36508829.3775     +841048.2637\n",
      "        24   -35730445.9776     +778383.3999\n",
      "        25   -34977196.1733     +753249.8043\n",
      "        26   -34227847.7189     +749348.4544\n",
      "        27   -33516582.6140     +711265.1049\n",
      "        28   -32861883.2750     +654699.3390\n",
      "        29   -32231614.4166     +630268.8584\n",
      "        30   -31607338.9380     +624275.4786\n",
      "        31   -31016816.4078     +590522.5302\n",
      "        32   -30474475.7133     +542340.6945\n",
      "        33   -29952666.7639     +521808.9494\n",
      "        34   -29435760.5741     +516906.1898\n",
      "        35   -28946495.0387     +489265.5354\n",
      "        36   -28496683.7354     +449811.3033\n",
      "        37   -28063309.6375     +433374.0979\n",
      "        38   -27633287.3040     +430022.3335\n",
      "        39   -27225902.3351     +407384.9689\n",
      "        40   -26851094.1250     +374808.2101\n",
      "        41   -26489539.3983     +361554.7267\n",
      "        42   -26130173.3235     +359366.0748\n",
      "        43   -25788652.0846     +341521.2389\n",
      "        44   -25473281.6389     +315370.4456\n",
      "        45   -25167997.2495     +305284.3895\n",
      "        46   -24863507.8590     +304489.3905\n",
      "        47   -24573148.3017     +290359.5573\n",
      "        48   -24304149.2973     +268999.0044\n",
      "        49   -24042940.2605     +261209.0368\n",
      "        50   -23781600.0245     +261340.2360\n",
      "        51   -23531618.7570     +249981.2675\n",
      "        52   -23299346.4713     +232272.2857\n",
      "        53   -23073163.5294     +226182.9419\n",
      "        54   -22846229.2836     +226934.2458\n",
      "        55   -22628553.1894     +217676.0942\n",
      "        56   -22425764.3096     +202788.8798\n",
      "        57   -22227793.6377     +197970.6719\n",
      "        58   -22028663.1217     +199130.5160\n",
      "        59   -21837175.9345     +191487.1872\n",
      "        60   -21658351.0259     +178824.9086\n",
      "        61   -21483364.0771     +174986.9488\n",
      "        62   -21306939.1652     +176424.9119\n",
      "        63   -21136893.0316     +170046.1336\n",
      "        64   -20977741.5595     +159151.4721\n",
      "        65   -20821677.4120     +156064.1476\n",
      "        66   -20664000.8918     +157676.5201\n",
      "        67   -20511711.0132     +152289.8786\n",
      "        68   -20368898.2205     +142812.7927\n",
      "        69   -20228592.6601     +140305.5603\n",
      "        70   -20086572.7793     +142019.8809\n",
      "        71   -19949152.0154     +137420.7639\n",
      "        72   -19820057.5407     +129094.4747\n",
      "        73   -19693017.0926     +127040.4481\n",
      "        74   -19564210.2862     +128806.8064\n",
      "        75   -19439369.9413     +124840.3448\n",
      "        76   -19321910.5027     +117459.4386\n",
      "        77   -19206147.1144     +115763.3884\n",
      "        78   -19088599.5147     +117547.5997\n",
      "        79   -18974504.2885     +114095.2262\n",
      "        80   -18867004.6921     +107499.5963\n",
      "        81   -18760915.4878     +106089.2043\n",
      "        82   -18653047.5875     +107867.9004\n",
      "        83   -18548209.9114     +104837.6761\n",
      "        84   -18449308.9538      +98900.9576\n",
      "        85   -18351588.3671      +97720.5867\n",
      "        86   -18252110.5691      +99477.7979\n",
      "        87   -18155313.0674      +96797.5018\n",
      "        88   -18063894.3218      +91418.7455\n",
      "        89   -17973469.3100      +90425.0119\n",
      "        90   -17881324.2292      +92145.0807\n",
      "        91   -17791600.3506      +89723.8786\n",
      "        92   -17706809.5769      +84790.7737\n",
      "        93   -17622888.6336      +83920.9433\n",
      "        94   -17537312.6064      +85576.0272\n",
      "        95   -17453900.3081      +83412.2983\n",
      "Training cooc:   0%|                                     | 0/10 [03:15<?, ?it/s]\n",
      "Model building:   0%|                                     | 0/3 [03:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,8) (11,11) ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 48>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     83\u001B[0m         preds \u001B[38;5;241m=\u001B[39m densehmm\u001B[38;5;241m.\u001B[39mpredict(Y_true, lengths)\n\u001B[1;32m     84\u001B[0m         perm \u001B[38;5;241m=\u001B[39m find_permutation(preds, X_true)\n\u001B[1;32m     86\u001B[0m         best_result[name]\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m     87\u001B[0m             {\n\u001B[1;32m     88\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m\"\u001B[39m: time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m hmm_monitor\u001B[38;5;241m.\u001B[39m_init_time,\n\u001B[1;32m     89\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogprob\u001B[39m\u001B[38;5;124m\"\u001B[39m: densehmm\u001B[38;5;241m.\u001B[39mscore(Y_true, lengths),\n\u001B[1;32m     90\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124macc\u001B[39m\u001B[38;5;124m\"\u001B[39m: (X_true \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39marray([perm[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m preds]))\u001B[38;5;241m.\u001B[39mmean(),\n\u001B[1;32m     91\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtv_transmat\u001B[39m\u001B[38;5;124m\"\u001B[39m: dtv(densehmm\u001B[38;5;241m.\u001B[39mtransmat_, A[perm, :][:, perm]),\n\u001B[1;32m     92\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtv_startprob\u001B[39m\u001B[38;5;124m\"\u001B[39m: dtv(densehmm\u001B[38;5;241m.\u001B[39mstartprob_, pi[perm]),\n\u001B[1;32m     93\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMAE_means\u001B[39m\u001B[38;5;124m\"\u001B[39m: (\u001B[38;5;28mabs\u001B[39m(mu[perm] \u001B[38;5;241m-\u001B[39m densehmm\u001B[38;5;241m.\u001B[39mmeans_[:, \u001B[38;5;241m0\u001B[39m]))\u001B[38;5;241m.\u001B[39mmean(),\n\u001B[1;32m     94\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMAE_sigma\u001B[39m\u001B[38;5;124m\"\u001B[39m: (\u001B[38;5;28mabs\u001B[39m(sigma\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)[perm] \u001B[38;5;241m-\u001B[39m densehmm\u001B[38;5;241m.\u001B[39mcovars_\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)))\u001B[38;5;241m.\u001B[39mmean(),\n\u001B[0;32m---> 95\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtv_omega\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mdtv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mempirical_cooc_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mY_disc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mnormal_cooc_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdensehmm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmeans_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdensehmm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcovars_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m             }\n\u001B[1;32m     98\u001B[0m         )\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mRESULT_DIR\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/best_result_s\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_T\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mT\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_n\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_simple_model\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msimple_model\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_l\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ml_fixed\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m    101\u001B[0m     json\u001B[38;5;241m.\u001B[39mdump(best_result, f, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[0;32m/ziob/klaudia/recommender_system/src/models/gaussian_dense_hmm/dense-hmm/code_dense_hmm/utils.py:286\u001B[0m, in \u001B[0;36mdtv\u001B[0;34m(a1, a2)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdtv\u001B[39m(a1, a2):\n\u001B[0;32m--> 286\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28mabs\u001B[39m(\u001B[43ma1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43ma2\u001B[49m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;241m/\u001B[39m a1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with shapes (8,8) (11,11) "
     ]
    }
   ],
   "source": [
    "## Evaluate models\n",
    "\n",
    "true_values = {\n",
    "    \"states\": X_true,\n",
    "    \"transmat\": A,\n",
    "    \"startprob\": pi,\n",
    "    \"means\": mu,\n",
    "    \"covars\": sigma\n",
    "}\n",
    "\n",
    "# HMMlearn\n",
    "best_result[\"HMMlearn\"] = list()\n",
    "wandb_params[\"init\"].update({\"job_type\": f\"n={n}-s={s}-T={s}-simple={simple_model}\",\n",
    "                             \"name\": f\"HMMlearn\"})\n",
    "wandb_params[\"config\"].update(dict(model=\"HMMlearn\", m=0, l=0, lr=0,\n",
    "                                   em_iter=em_iter(n), cooc_epochs=0,\n",
    "                                   epochs=0), scheduler=False, simple_model=simple_model)\n",
    "nodes_tmp = mu\n",
    "nodes = np.concatenate([np.array([-np.infty, Y_true.min()]),\n",
    "                        (nodes_tmp[1:] + nodes_tmp[:-1]).reshape(-1) / 2,\n",
    "                        np.array([Y_true.max(), np.infty])])\n",
    "Y_disc = (Y_true > nodes.reshape(1, -1)).sum(axis=-1).reshape(-1, 1)\n",
    "\n",
    "for _ in range(10):\n",
    "    hmm_monitor = HMMLoggingMonitor(tol=TOLERANCE, n_iter=0, verbose=True,\n",
    "                                    wandb_log=True, wandb_params=wandb_params, true_vals=true_values,\n",
    "                                    log_config={'metrics_after_convergence': True})\n",
    "    hmm_model = hmm.GaussianHMM(n, n_iter=em_iter(n))\n",
    "    hmm_model.monitor_ = hmm_monitor\n",
    "    hmm_model.fit(Y_true, lengths)\n",
    "\n",
    "    preds = hmm_model.predict(Y_true, lengths)\n",
    "    perm = find_permutation(preds, X_true)\n",
    "\n",
    "    best_result[\"HMMlearn\"].append(\n",
    "        {\n",
    "            \"time\": time.perf_counter() - hmm_monitor._init_time,\n",
    "            \"logprob\": hmm_model.score(Y_true, lengths),\n",
    "            \"acc\": (X_true == np.array([perm[i] for i in preds])).mean(),\n",
    "            \"dtv_transmat\": dtv(hmm_model.transmat_, A[perm, :][:, perm]),\n",
    "            \"dtv_startprob\": dtv(hmm_model.startprob_, pi[perm]),\n",
    "            \"MAE_means\": (abs(mu[perm] - hmm_model.means_[:, 0])).mean(),\n",
    "            \"MAE_sigma\": (abs(sigma.reshape(-1)[perm] - hmm_model.covars_.reshape(-1))).mean(),\n",
    "            \"dtv_omega\": dtv(empirical_cooc_prob(Y_disc, n, lengths),\n",
    "                             normal_cooc_prob(hmm_model.means_.reshape(-1), hmm_model.covars_.reshape(-1), nodes, A))\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Custom models\n",
    "for name in tqdm.tqdm([\"cooc\", \"dense\", \"dense_em\"],  desc=\"Model building\"):\n",
    "    model = models[name]\n",
    "    monitor = monitors[name]\n",
    "    alg = algs[name]\n",
    "    params = best_params[name]\n",
    "    best_result[name] = list()\n",
    "    wandb_params[\"init\"].update({\"job_type\": f\"n={n}-s={s}-T={s}-simple={simple_model}\",\n",
    "                                 \"name\": f\"name-l={params['l_param']}-lr={params['cooc_lr_param']}-epochs={params['cooc_epochs_param']}\"})\n",
    "    wandb_params[\"config\"].update(dict(model=\"dense_cooc\", m=0, l=int(params['l_param']), lr=params['cooc_lr_param'],\n",
    "                                       em_iter=em_iter(n), cooc_epochs=params['cooc_epochs_param'],\n",
    "                                       epochs=params['cooc_epochs_param']), scheduler=True,\n",
    "                                  simple_model=simple_model)\n",
    "\n",
    "    for _ in tqdm.tqdm(range(10), desc=f\"Training {name}\"):\n",
    "        hmm_monitor = monitor(tol=TOLERANCE, n_iter=0, verbose=True,\n",
    "                              wandb_log=True, wandb_params=wandb_params, true_vals=true_values,\n",
    "                              log_config={'metrics_after_convergence': True})\n",
    "        # kmeans = KMeans(n_clusters=n, random_state=0).fit(Y_true)\n",
    "        densehmm = model(n, mstep_config={'cooc_epochs': params['cooc_epochs_param'],\n",
    "                                          'cooc_lr': params['cooc_lr_param'],\n",
    "                                          \"l_uz\": int(params['l_param']),\n",
    "                                          'loss_type': 'square',\n",
    "                                          'scheduler': em_scheduler},\n",
    "                         covariance_type='diag', logging_monitor=hmm_monitor, nodes=nodes,\n",
    "                         init_params=\"\", params=\"stmc\", early_stopping=False, opt_schemes={\"cooc\"},\n",
    "                         discrete_observables=m)\n",
    "        if alg == \"cooc\":\n",
    "            densehmm.fit_coocs(Y_true, lengths)\n",
    "        else:\n",
    "            densehmm.fit(Y_true, lengths)\n",
    "\n",
    "        preds = densehmm.predict(Y_true, lengths)\n",
    "        perm = find_permutation(preds, X_true)\n",
    "\n",
    "        best_result[name].append(\n",
    "            {\n",
    "                \"time\": time.perf_counter() - hmm_monitor._init_time,\n",
    "                \"logprob\": densehmm.score(Y_true, lengths),\n",
    "                \"acc\": (X_true == np.array([perm[i] for i in preds])).mean(),\n",
    "                \"dtv_transmat\": dtv(densehmm.transmat_, A[perm, :][:, perm]),\n",
    "                \"dtv_startprob\": dtv(densehmm.startprob_, pi[perm]),\n",
    "                \"MAE_means\": (abs(mu[perm] - densehmm.means_[:, 0])).mean(),\n",
    "                \"MAE_sigma\": (abs(sigma.reshape(-1)[perm] - densehmm.covars_.reshape(-1))).mean(),\n",
    "                \"dtv_omega\": dtv(empirical_cooc_prob(Y_disc, n, lengths),\n",
    "                                  normal_cooc_prob(densehmm.means_.reshape(-1), densehmm.covars_.reshape(-1), nodes, A))\n",
    "            }\n",
    "        )\n",
    "\n",
    "with open(f\"{RESULT_DIR}/best_result_s{s}_T{T}_n{n}_simple_model{simple_model}_l{l_fixed}.json\", \"w\") as f:\n",
    "    json.dump(best_result, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        27     -292834.6472          +0.0000\n"
     ]
    }
   ],
   "source": [
    "# Provide data\n",
    "all_files = os.listdir(RESULT_DIR)\n",
    "\n",
    "results = [s for s in all_files if len(s.split(\"_\")) == 6]\n",
    "studies = [s for s in all_files if len(s.split(\"_\")) == 7]\n",
    "\n",
    "cases = list(set([\"_\".join(s.split(\"_\")[1:-1]) for s in studies]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read all data\n",
    "experiment = dict(studies  =dict(l_fixed=dict(),  l_tuned=dict()),\n",
    "                  summaries=dict(l_fixed=dict(),  l_tuned=dict()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for c in cases:\n",
    "    with open(f\"{RESULT_DIR}/optuna_{c}_lTrue.pkl\", \"rb\") as f:\n",
    "        experiment[\"studies\"][\"l_fixed\"][c] = joblib.load(f)\n",
    "    with open(f\"{RESULT_DIR}/optuna_{c}_lFalse.pkl\", \"rb\") as f:\n",
    "        experiment[\"studies\"][\"l_tuned\"][c] = joblib.load(f)\n",
    "    with open(f\"{RESULT_DIR}/best_result_{c}_lTrue.json\", \"r\") as f:\n",
    "        experiment[\"summaries\"][\"l_fixed\"][c] = json.load(f)\n",
    "    with open(f\"{RESULT_DIR}/best_result_{c}_lFalse.json\", \"r\") as f:\n",
    "        experiment[\"summaries\"][\"l_tuned\"][c] = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare tunning methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "for c in cases:\n",
    "    display(optuna.visualization.plot_param_importances(experiment[\"studies\"][\"l_fixed\"][c],\n",
    "                                                        target=lambda t: t.values[0], target_name=\"flops\",  title=\"Fixed\"))\n",
    "    display(optuna.visualization.plot_param_importances(experiment[\"studies\"][\"l_tuned\"][c],\n",
    "                                                        target=lambda t: t.values[0], target_name=\"flops\", title=\"Tuned\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# l zafixowane versus wyniki hiperparametryzacji zależnie od l\n",
    "for c in cases:\n",
    "    no_trials = len(experiment[\"studies\"][\"l_fixed\"][c].trials)\n",
    "    x = [experiment[\"studies\"][\"l_fixed\"][c].trials[i].params['l_param'] for i in range(no_trials)]\n",
    "    y = [experiment[\"studies\"][\"l_fixed\"][c].trials[i].values[0] for i in range(no_trials)]\n",
    "    name = cases.split(\"_\")[0]\n",
    "    sns.violinplot(x, y)\n",
    "    plt.xlabel(\"l\")\n",
    "    plt.ylabel(\"log-likelihood\")\n",
    "    plt.title(f\"{name} (when fixed l={int(np.ceil(8 / 3))})\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# s, T, n, simple_model = 100, 40, 4, True\n",
    "#\n",
    "# with open(f\"gaussian_dense_hmm_benchmark/fit_coocs_ll_mini-2022-8-12/optuna_s{s}_T{T}_n{n}_simple_model{simple_model}.pkl\",  \"rb\") as f:\n",
    "#     study = joblib.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare  results of all methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# with open(f\"gaussian_dense_hmm_benchmark/fit_coocs_ll_mini-2022-8-12/best_result_s{s}_T{T}_n{n}_simple_model{simple_model}.json\",  \"r\") as f:\n",
    "#     best_results = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "#  tabularise results\n",
    "for c in cases:\n",
    "    display(f'\\n\\n### {\" \".join(c.split(\"_\"))}')\n",
    "    display(pd.DataFrame(experiment[\"summaries\"][\"l_fixed\"][c]).style.set_caption(\"l fixed\"))\n",
    "    display(pd.DataFrame(experiment[\"summaries\"][\"l_tuned\"][c]).style.set_caption(\"l tuned\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train co-oc + EM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Use the same parameters and provide time benchmarks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s, T, n, pi, A, mu, sigma, result, true_values, wandb_params, X_true, Y_true, lengths, data, em_scheduler = init_experiment(dsize=(100, 100, 8), simple_model=True)\n",
    "\n",
    "\n",
    "def to_discrete(X, m):\n",
    "    kmeans = KMeans(n_clusters=m, random_state=0).fit(Y_true)\n",
    "    nodes_tmp = np.sort(kmeans.cluster_centers_, axis=0)\n",
    "    nodes = np.concatenate([(nodes_tmp[1:] + nodes_tmp[:-1]) / 2, np.array([[np.infty]])])\n",
    "    return (X > nodes.reshape(1, -1)).sum(axis=-1).reshape(-1, 1), nodes.reshape(-1)\n",
    "\n",
    "\n",
    "Y_disc, nodes = to_discrete(Y_true, m=n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for  _  in range(10):\n",
    "    # TODO: read parameters from dense cooc and dense em\n",
    "    cooc_params = experiment[\"studies\"][\"l_fixed\"][c].best_params  # TODO: c\n",
    "    em_params   = experiment[\"studies\"][\"l_fixed\"][c].best_params  # TODO: c\n",
    "    mstep_cofig = {\"cooc_lr\": cooc_params['cooc_lr_param'],\n",
    "                   \"cooc_epochs\": cooc_params['cooc_epochs_param'],\n",
    "                   \"l_uz\": cooc_params['l_param'],\n",
    "                   \"em_params\":  em_params['cooc_lr_param'],\n",
    "                   \"em_epochs\": em_params['cooc_epochs_param'],\n",
    "                   \"loss_type\": 'square',\n",
    "                   \"scheduler\": em_scheduler}\n",
    "    wandb_params[\"init\"].update({\"name\": f\"dense-cooc+em\"})\n",
    "    hmm_monitor = HMMLoggingMonitor(tol=TOLERANCE, n_iter=0, verbose=True,\n",
    "                                    wandb_log=True, wandb_params=wandb_params, true_vals=true_values,\n",
    "                                    log_config={'metrics_after_convergence': True})\n",
    "    densehmm = GaussianDenseHMM(n, mstep_config=mstep_cofig,\n",
    "                                covariance_type='diag', opt_schemes={\"cooc\"},\n",
    "                                nodes=np.concatenate([np.array([-np.infty]), nodes]),\n",
    "                                discrete_observables=n, em_iter=20,\n",
    "                                logging_monitor=hmm_monitor,\n",
    "                                init_params=\"\", params=\"stmc\", early_stopping=True)\n",
    "    densehmm.means_ = mu.reshape(-1, 1)\n",
    "    start = time.perf_counter()\n",
    "    densehmm.fit_coocs(Y_true, lengths)\n",
    "    densehmm.fit(Y_true, lengths)\n",
    "    time_tmp = time.perf_counter() - start\n",
    "\n",
    "#  Results in wanbd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}