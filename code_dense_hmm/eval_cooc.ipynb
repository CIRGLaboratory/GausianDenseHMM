{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 07:41:21.057335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-18 07:41:21.057397: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /ziob/klaudia/miniconda3/envs/hmm/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import  pickle\n",
    "import joblib\n",
    "import optuna\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from eval_utils import *\n",
    "from models_gaussian import GaussianDenseHMM, HMMLoggingMonitor, DenseHMMLoggingMonitor\n",
    "from models_gaussian_A import GaussianDenseHMM as CoocHMM\n",
    "from hmmlearn import hmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "t = time.localtime()\n",
    "RESULT_DIR = f'gaussian_dense_hmm_benchmark/eval-cooc-{t.tm_year}-{t.tm_mon}-{t.tm_mday}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have examined the efficiency of co-occurence based learning methods for Gaussian HMM. This notebook contains a comparison of:\n",
    "\n",
    "- standard Gaussian Hidden Markov Model implementation,\n",
    "- co-occurrence based larning for Gaussian Hidden Markov Model,\n",
    "- EM learning for GaussianDenseHHMM,\n",
    "- co-occurrence based learning for GaussianDenseHMM.\n",
    "\n",
    "The dense representation was examined with fixed and tuned embedding length."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "n = 8\n",
    "s = 100\n",
    "T = 1000\n",
    "simple_model = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "l_fixed = True\n",
    "\n",
    "RESULT_DIR = f'gaussian_dense_hmm_benchmark/eval-cooc-{t.tm_year}-{t.tm_mon}-{17}'\n",
    "with open(f\"{RESULT_DIR}/optuna_cooc_s{s}_T{T}_n{n}_simple_model{simple_model}_l{l_fixed}.pkl\", \"rb\") as f:\n",
    "    study = joblib.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    cooc_lr_param  cooc_epochs_param          mean           std\n0        0.007055              95252 -1.029042e+08  4.989413e+07\n1        0.000372              22013 -1.258788e+08  8.937642e+07\n2        0.016005              14357 -6.724162e+07  1.405187e+07\n3        0.315334              94224 -8.523348e+07  6.216957e+07\n4        0.054786              15321 -8.100231e+07  1.229705e+07\n5        0.001338              61685 -1.059174e+08  5.560698e+07\n6        0.000292              54599 -6.600827e+07  9.538663e+06\n7        0.070272              71114 -7.066690e+07  3.602548e+07\n8        0.312263              43095 -7.776879e+07  1.773118e+07\n9        0.000237              26975 -8.915181e+07  4.766469e+07\n10       0.001001              39586 -7.212859e+07  2.600582e+07\n11       0.446506              99209 -1.182312e+08  7.659809e+07\n12       0.000111              50020 -7.327907e+07  1.724211e+07\n13       0.000775              73176 -9.530288e+07  2.544203e+07\n14       0.070398              91875 -1.056092e+08  5.346814e+07\n15       0.000594              71827 -8.024238e+07  2.248703e+07\n16       0.000192              17909 -7.972843e+07  3.615685e+07\n17       0.002948              38099 -8.165278e+07  4.503880e+07\n18       0.201781              50368 -2.739705e+08  5.020861e+08\n19       0.002612              31394 -9.500772e+07  3.092008e+07\n20       0.013903              36177 -7.955373e+07  5.931536e+07\n21       0.037838              96577 -8.763162e+07  1.914613e+07\n22       0.419299              29103 -1.902856e+08  3.039974e+08\n23       0.006044              68533 -8.209136e+07  3.512586e+07\n24       0.000963              89393 -9.296827e+07  3.328557e+07\n25       0.074828              53265 -6.755254e+07  3.986388e+07\n26       0.024116              93694 -9.855420e+07  3.681705e+07\n27       0.001513              37451 -9.688019e+07  6.498089e+07\n28       0.060725              94151 -5.013962e+07  3.025958e+07\n29       0.004612              50432 -9.595474e+07  4.684733e+07\n30       0.012826              94882 -8.017866e+07  2.309183e+07\n31       0.000971              14429 -7.977648e+07  4.249492e+07",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cooc_lr_param</th>\n      <th>cooc_epochs_param</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.007055</td>\n      <td>95252</td>\n      <td>-1.029042e+08</td>\n      <td>4.989413e+07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000372</td>\n      <td>22013</td>\n      <td>-1.258788e+08</td>\n      <td>8.937642e+07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.016005</td>\n      <td>14357</td>\n      <td>-6.724162e+07</td>\n      <td>1.405187e+07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.315334</td>\n      <td>94224</td>\n      <td>-8.523348e+07</td>\n      <td>6.216957e+07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.054786</td>\n      <td>15321</td>\n      <td>-8.100231e+07</td>\n      <td>1.229705e+07</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.001338</td>\n      <td>61685</td>\n      <td>-1.059174e+08</td>\n      <td>5.560698e+07</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000292</td>\n      <td>54599</td>\n      <td>-6.600827e+07</td>\n      <td>9.538663e+06</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.070272</td>\n      <td>71114</td>\n      <td>-7.066690e+07</td>\n      <td>3.602548e+07</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.312263</td>\n      <td>43095</td>\n      <td>-7.776879e+07</td>\n      <td>1.773118e+07</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000237</td>\n      <td>26975</td>\n      <td>-8.915181e+07</td>\n      <td>4.766469e+07</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.001001</td>\n      <td>39586</td>\n      <td>-7.212859e+07</td>\n      <td>2.600582e+07</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.446506</td>\n      <td>99209</td>\n      <td>-1.182312e+08</td>\n      <td>7.659809e+07</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.000111</td>\n      <td>50020</td>\n      <td>-7.327907e+07</td>\n      <td>1.724211e+07</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.000775</td>\n      <td>73176</td>\n      <td>-9.530288e+07</td>\n      <td>2.544203e+07</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.070398</td>\n      <td>91875</td>\n      <td>-1.056092e+08</td>\n      <td>5.346814e+07</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.000594</td>\n      <td>71827</td>\n      <td>-8.024238e+07</td>\n      <td>2.248703e+07</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.000192</td>\n      <td>17909</td>\n      <td>-7.972843e+07</td>\n      <td>3.615685e+07</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.002948</td>\n      <td>38099</td>\n      <td>-8.165278e+07</td>\n      <td>4.503880e+07</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.201781</td>\n      <td>50368</td>\n      <td>-2.739705e+08</td>\n      <td>5.020861e+08</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.002612</td>\n      <td>31394</td>\n      <td>-9.500772e+07</td>\n      <td>3.092008e+07</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.013903</td>\n      <td>36177</td>\n      <td>-7.955373e+07</td>\n      <td>5.931536e+07</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.037838</td>\n      <td>96577</td>\n      <td>-8.763162e+07</td>\n      <td>1.914613e+07</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.419299</td>\n      <td>29103</td>\n      <td>-1.902856e+08</td>\n      <td>3.039974e+08</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.006044</td>\n      <td>68533</td>\n      <td>-8.209136e+07</td>\n      <td>3.512586e+07</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.000963</td>\n      <td>89393</td>\n      <td>-9.296827e+07</td>\n      <td>3.328557e+07</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.074828</td>\n      <td>53265</td>\n      <td>-6.755254e+07</td>\n      <td>3.986388e+07</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.024116</td>\n      <td>93694</td>\n      <td>-9.855420e+07</td>\n      <td>3.681705e+07</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.001513</td>\n      <td>37451</td>\n      <td>-9.688019e+07</td>\n      <td>6.498089e+07</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.060725</td>\n      <td>94151</td>\n      <td>-5.013962e+07</td>\n      <td>3.025958e+07</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.004612</td>\n      <td>50432</td>\n      <td>-9.595474e+07</td>\n      <td>4.684733e+07</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.012826</td>\n      <td>94882</td>\n      <td>-8.017866e+07</td>\n      <td>2.309183e+07</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.000971</td>\n      <td>14429</td>\n      <td>-7.977648e+07</td>\n      <td>4.249492e+07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_res = pd.DataFrame([{**t.params, \"mean\": t.values[0], \"std\": t.values[1]} for t in study.trials])\n",
    "study_res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='mean', ylabel='std'>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=study_res, x=\"mean\", y=\"std\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cooc_lr_param': 0.060724553741338755, 'cooc_epochs_param': 94151}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study_res.sort_values(\"mean\").iloc[-1, :2].to_dict()\n",
    "best_params['cooc_epochs_param'] = int(best_params['cooc_epochs_param'])\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "best_result = {}\n",
    "s, T, n, pi, A, mu, sigma, result, true_values, wandb_params, X_true, Y_true, lengths, _, em_scheduler = init_experiment((s, T, n), simple_model)\n",
    "nodes = np.concatenate([np.array([-np.infty, Y_true.min()]),\n",
    "                        (mu[1:] + mu[:-1]) / 2,\n",
    "                        np.array([Y_true.max(), np.infty])])\n",
    "m = nodes.shape[0] - 1\n",
    "\n",
    "models = dict(cooc=CoocHMM, dense=GaussianDenseHMM, dense_em=GaussianDenseHMM)\n",
    "monitors = dict(cooc=DenseHMMLoggingMonitor, dense=DenseHMMLoggingMonitor, dense_em=DenseHMMLoggingMonitor)\n",
    "algs = dict(cooc=\"cooc\", dense=\"cooc\", dense_em=\"em\")\n",
    "\n",
    "## Tune hyper-parameters\n",
    "l = np.ceil(n / 3) if l_fixed else None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "lengths = np.array(lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def _lengths_iterator(seqs, lengths):\n",
    "    n_seqs = len(lengths)\n",
    "    left, right = 0, 0\n",
    "\n",
    "    for i in range(len(lengths)):\n",
    "        right += lengths[i]\n",
    "        yield seqs[left:right]\n",
    "        left += lengths[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:23o873nb) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.052 MB of 0.052 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeb997fcf8444c02a3c7f422a41a41bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>time</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>total_log_prob</td><td>▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>time</td><td>25.56795</td></tr><tr><td>total_log_prob</td><td>-292834.6472</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">HMMlearn</strong>: <a href=\"https://wandb.ai/cirglaboratory/gaussian-dense-hmm/runs/23o873nb\" target=\"_blank\">https://wandb.ai/cirglaboratory/gaussian-dense-hmm/runs/23o873nb</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20220818_074955-23o873nb/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:23o873nb). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.13.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.21"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/ziob/klaudia/recommender_system/src/models/gaussian_dense_hmm/dense-hmm/code_dense_hmm/wandb/run-20220818_075525-19pw1ade</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/cirglaboratory/gaussian-dense-hmm/runs/19pw1ade\" target=\"_blank\">HMMlearn</a></strong> to <a href=\"https://wandb.ai/cirglaboratory/gaussian-dense-hmm\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -471976.9190             +nan\n",
      "         2     -455362.5670      +16614.3520\n",
      "         3     -450188.9328       +5173.6342\n",
      "         4     -446124.3595       +4064.5733\n",
      "         5     -443737.3090       +2387.0505\n",
      "         6     -442249.8347       +1487.4742\n",
      "         7     -440975.0469       +1274.7878\n",
      "         8     -439203.1699       +1771.8770\n",
      "         9     -435442.3169       +3760.8530\n",
      "        10     -427009.4034       +8432.9135\n",
      "        11     -412859.7190      +14149.6844\n",
      "        12     -390204.2685      +22655.4505\n",
      "        13     -372871.3944      +17332.8741\n",
      "        14     -361244.9872      +11626.4072\n",
      "        15     -356265.4927       +4979.4945\n",
      "        16     -346042.2263      +10223.2664\n",
      "        17     -330314.8560      +15727.3703\n",
      "        18     -316007.7826      +14307.0734\n",
      "        19     -312715.6990       +3292.0835\n",
      "        20     -311179.1666       +1536.5324\n",
      "        21     -308610.2378       +2568.9288\n",
      "        22     -303801.1558       +4809.0819\n",
      "        23     -298721.4839       +5079.6719\n",
      "        24     -295440.1610       +3281.3229\n",
      "        25     -292925.3238       +2514.8372\n",
      "        26     -292834.6472         +90.6766\n"
     ]
    }
   ],
   "source": [
    "## Evaluate models\n",
    "\n",
    "true_values = {\n",
    "    \"states\": X_true,\n",
    "    \"transmat\": A,\n",
    "    \"startprob\": pi,\n",
    "    \"means\": mu,\n",
    "    \"covars\": sigma\n",
    "}\n",
    "\n",
    "# HMMlearn\n",
    "best_result[\"HMMlearn\"] = list()\n",
    "wandb_params[\"init\"].update({\"job_type\": f\"n={n}-s={s}-T={s}-simple={simple_model}\",\n",
    "                             \"name\": f\"HMMlearn\"})\n",
    "wandb_params[\"config\"].update(dict(model=\"HMMlearn\", m=0, l=0, lr=0,\n",
    "                                   em_iter=em_iter(n), cooc_epochs=0,\n",
    "                                   epochs=0), scheduler=False, simple_model=simple_model)\n",
    "nodes_tmp = np.sort(mu)\n",
    "nodes = np.concatenate([(nodes_tmp[1:] + nodes_tmp[:-1]) / 2, np.array([np.infty])])\n",
    "Y_disc = (Y_true > nodes.reshape(1, -1)).sum(axis=-1).reshape(-1, 1)\n",
    "\n",
    "for _ in range(10):\n",
    "    hmm_monitor = HMMLoggingMonitor(tol=TOLERANCE, n_iter=0, verbose=True,\n",
    "                                    wandb_log=True, wandb_params=wandb_params, true_vals=true_values,\n",
    "                                    log_config={'metrics_after_convergence': True})\n",
    "    hmm_model = hmm.GaussianHMM(n, n_iter=em_iter(n))\n",
    "    hmm_model.monitor_ = hmm_monitor\n",
    "    hmm_model.fit(Y_true, lengths)\n",
    "\n",
    "    preds = hmm_model.predict(Y_true, lengths)\n",
    "    perm = find_permutation(preds, X_true)\n",
    "\n",
    "    best_result[\"HMMlearn\"].append(\n",
    "        {\n",
    "            \"time\": time.perf_counter() - hmm_monitor._init_time,\n",
    "            \"logprob\": hmm_model.score(Y_true, lengths),\n",
    "            \"acc\": (X_true == np.array([perm[i] for i in preds])).mean(),\n",
    "            \"dtv_transmat\": dtv(hmm_model.transmat_, A[perm, :][:, perm]),\n",
    "            \"dtv_startprob\": dtv(hmm_model.startprob_, pi[perm]),\n",
    "            \"MAE_means\": (abs(mu[perm] - hmm_model.means_[:, 0])).mean(),\n",
    "            \"MAE_sigma\": (abs(sigma.reshape(-1)[perm] - hmm_model.covars_.reshape(-1))).mean(),\n",
    "            \"dtv_omega\": dtv(empirical_cooc_prob(Y_disc, n, lengths),\n",
    "                             normal_cooc_prob(hmm_model.means_.reshape(-1), hmm_model.covars_.reshape(-1), nodes, A))\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Custom models\n",
    "for name in tqdm.tqdm([\"cooc\", \"dense\", \"dense_em\"],  desc=\"Model building\"):\n",
    "    model = models[name]\n",
    "    monitor = monitors[name]\n",
    "    alg = algs[name]\n",
    "    params = best_params[name]\n",
    "    best_result[name] = list()\n",
    "    wandb_params[\"init\"].update({\"job_type\": f\"n={n}-s={s}-T={s}-simple={simple_model}\",\n",
    "                                 \"name\": f\"name-l={params['l_param']}-lr={params['cooc_lr_param']}-epochs={params['cooc_epochs_param']}\"})\n",
    "    wandb_params[\"config\"].update(dict(model=\"dense_cooc\", m=0, l=int(params['l_param']), lr=params['cooc_lr_param'],\n",
    "                                       em_iter=em_iter(n), cooc_epochs=params['cooc_epochs_param'],\n",
    "                                       epochs=params['cooc_epochs_param']), scheduler=True,\n",
    "                                  simple_model=simple_model)\n",
    "\n",
    "    for _ in tqdm.tqdm(range(10), desc=f\"Training {name}\"):\n",
    "        hmm_monitor = monitor(tol=TOLERANCE, n_iter=0, verbose=True,\n",
    "                              wandb_log=True, wandb_params=wandb_params, true_vals=true_values,\n",
    "                              log_config={'metrics_after_convergence': True})\n",
    "        # kmeans = KMeans(n_clusters=n, random_state=0).fit(Y_true)\n",
    "        nodes_tmp = mu\n",
    "        nodes = np.concatenate([np.array([-np.infty, Y_true.min()]),\n",
    "                                (nodes_tmp[1:] + nodes_tmp[:-1]).reshape(-1) / 2,\n",
    "                                np.array([Y_true.max(), np.infty])])\n",
    "        densehmm = model(n, mstep_config={'cooc_epochs': params['cooc_epochs_param'],\n",
    "                                          'cooc_lr': params['cooc_lr_param'],\n",
    "                                          \"l_uz\": int(params['l_param']),\n",
    "                                          'loss_type': 'square',\n",
    "                                          'scheduler': em_scheduler},\n",
    "                         covariance_type='diag', logging_monitor=hmm_monitor, nodes=nodes,\n",
    "                         init_params=\"\", params=\"stmc\", early_stopping=False, opt_schemes={\"cooc\"},\n",
    "                         discrete_observables=m)\n",
    "        if alg == \"cooc\":\n",
    "            densehmm.fit_coocs(Y_true, lengths)\n",
    "        else:\n",
    "            densehmm.fit(Y_true, lengths)\n",
    "\n",
    "        preds = densehmm.predict(Y_true, lengths)\n",
    "        perm = find_permutation(preds, X_true)\n",
    "\n",
    "        best_result[name].append(\n",
    "            {\n",
    "                \"time\": time.perf_counter() - hmm_monitor._init_time,\n",
    "                \"logprob\": densehmm.score(Y_true, lengths),\n",
    "                \"acc\": (X_true == np.array([perm[i] for i in preds])).mean(),\n",
    "                \"dtv_transmat\": dtv(densehmm.transmat_, A[perm, :][:, perm]),\n",
    "                \"dtv_startprob\": dtv(densehmm.startprob_, pi[perm]),\n",
    "                \"MAE_means\": (abs(mu[perm] - densehmm.means_[:, 0])).mean(),\n",
    "                \"MAE_sigma\": (abs(sigma.reshape(-1)[perm] - densehmm.covars_.reshape(-1))).mean(),\n",
    "                \"dtv_omega\": dtv(empirical_cooc_prob(Y_disc, n, lengths),\n",
    "                                  normal_cooc_prob(densehmm.means_.reshape(-1), densehmm.covars_.reshape(-1), nodes, A))\n",
    "            }\n",
    "        )\n",
    "\n",
    "with open(f\"{RESULT_DIR}/best_result_s{s}_T{T}_n{n}_simple_model{simple_model}_l{l_fixed}.json\", \"w\") as f:\n",
    "    json.dump(best_result, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Provide data\n",
    "all_files = os.listdir(RESULT_DIR)\n",
    "\n",
    "results = [s for s in all_files if len(s.split(\"_\")) == 6]\n",
    "studies = [s for s in all_files if len(s.split(\"_\")) == 7]\n",
    "\n",
    "cases = list(set([\"_\".join(s.split(\"_\")[1:-1]) for s in studies]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read all data\n",
    "experiment = dict(studies  =dict(l_fixed=dict(),  l_tuned=dict()),\n",
    "                  summaries=dict(l_fixed=dict(),  l_tuned=dict()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for c in cases:\n",
    "    with open(f\"{RESULT_DIR}/optuna_{c}_lTrue.pkl\", \"rb\") as f:\n",
    "        experiment[\"studies\"][\"l_fixed\"][c] = joblib.load(f)\n",
    "    with open(f\"{RESULT_DIR}/optuna_{c}_lFalse.pkl\", \"rb\") as f:\n",
    "        experiment[\"studies\"][\"l_tuned\"][c] = joblib.load(f)\n",
    "    with open(f\"{RESULT_DIR}/best_result_{c}_lTrue.json\", \"r\") as f:\n",
    "        experiment[\"summaries\"][\"l_fixed\"][c] = json.load(f)\n",
    "    with open(f\"{RESULT_DIR}/best_result_{c}_lFalse.json\", \"r\") as f:\n",
    "        experiment[\"summaries\"][\"l_tuned\"][c] = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare tunning methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "for c in cases:\n",
    "    display(optuna.visualization.plot_param_importances(experiment[\"studies\"][\"l_fixed\"][c],\n",
    "                                                        target=lambda t: t.values[0], target_name=\"flops\",  title=\"Fixed\"))\n",
    "    display(optuna.visualization.plot_param_importances(experiment[\"studies\"][\"l_tuned\"][c],\n",
    "                                                        target=lambda t: t.values[0], target_name=\"flops\", title=\"Tuned\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# l zafixowane versus wyniki hiperparametryzacji zależnie od l\n",
    "for c in cases:\n",
    "    no_trials = len(experiment[\"studies\"][\"l_fixed\"][c].trials)\n",
    "    x = [experiment[\"studies\"][\"l_fixed\"][c].trials[i].params['l_param'] for i in range(no_trials)]\n",
    "    y = [experiment[\"studies\"][\"l_fixed\"][c].trials[i].values[0] for i in range(no_trials)]\n",
    "    name = cases.split(\"_\")[0]\n",
    "    sns.violinplot(x, y)\n",
    "    plt.xlabel(\"l\")\n",
    "    plt.ylabel(\"log-likelihood\")\n",
    "    plt.title(f\"{name} (when fixed l={int(np.ceil(8 / 3))})\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# s, T, n, simple_model = 100, 40, 4, True\n",
    "#\n",
    "# with open(f\"gaussian_dense_hmm_benchmark/fit_coocs_ll_mini-2022-8-12/optuna_s{s}_T{T}_n{n}_simple_model{simple_model}.pkl\",  \"rb\") as f:\n",
    "#     study = joblib.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare  results of all methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# with open(f\"gaussian_dense_hmm_benchmark/fit_coocs_ll_mini-2022-8-12/best_result_s{s}_T{T}_n{n}_simple_model{simple_model}.json\",  \"r\") as f:\n",
    "#     best_results = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "#  tabularise results\n",
    "for c in cases:\n",
    "    display(f'\\n\\n### {\" \".join(c.split(\"_\"))}')\n",
    "    display(pd.DataFrame(experiment[\"summaries\"][\"l_fixed\"][c]).style.set_caption(\"l fixed\"))\n",
    "    display(pd.DataFrame(experiment[\"summaries\"][\"l_tuned\"][c]).style.set_caption(\"l tuned\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train co-oc + EM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Use the same parameters and provide time benchmarks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s, T, n, pi, A, mu, sigma, result, true_values, wandb_params, X_true, Y_true, lengths, data, em_scheduler = init_experiment(dsize=(100, 100, 8), simple_model=True)\n",
    "\n",
    "\n",
    "def to_discrete(X, m):\n",
    "    kmeans = KMeans(n_clusters=m, random_state=0).fit(Y_true)\n",
    "    nodes_tmp = np.sort(kmeans.cluster_centers_, axis=0)\n",
    "    nodes = np.concatenate([(nodes_tmp[1:] + nodes_tmp[:-1]) / 2, np.array([[np.infty]])])\n",
    "    return (X > nodes.reshape(1, -1)).sum(axis=-1).reshape(-1, 1), nodes.reshape(-1)\n",
    "\n",
    "\n",
    "Y_disc, nodes = to_discrete(Y_true, m=n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for  _  in range(10):\n",
    "    # TODO: read parameters from dense cooc and dense em\n",
    "    cooc_params = experiment[\"studies\"][\"l_fixed\"][c].best_params  # TODO: c\n",
    "    em_params   = experiment[\"studies\"][\"l_fixed\"][c].best_params  # TODO: c\n",
    "    mstep_cofig = {\"cooc_lr\": cooc_params['cooc_lr_param'],\n",
    "                   \"cooc_epochs\": cooc_params['cooc_epochs_param'],\n",
    "                   \"l_uz\": cooc_params['l_param'],\n",
    "                   \"em_params\":  em_params['cooc_lr_param'],\n",
    "                   \"em_epochs\": em_params['cooc_epochs_param'],\n",
    "                   \"loss_type\": 'square',\n",
    "                   \"scheduler\": em_scheduler}\n",
    "    wandb_params[\"init\"].update({\"name\": f\"dense-cooc+em\"})\n",
    "    hmm_monitor = HMMLoggingMonitor(tol=TOLERANCE, n_iter=0, verbose=True,\n",
    "                                    wandb_log=True, wandb_params=wandb_params, true_vals=true_values,\n",
    "                                    log_config={'metrics_after_convergence': True})\n",
    "    densehmm = GaussianDenseHMM(n, mstep_config=mstep_cofig,\n",
    "                                covariance_type='diag', opt_schemes={\"cooc\"},\n",
    "                                nodes=np.concatenate([np.array([-np.infty]), nodes]),\n",
    "                                discrete_observables=n, em_iter=20,\n",
    "                                logging_monitor=hmm_monitor,\n",
    "                                init_params=\"\", params=\"stmc\", early_stopping=True)\n",
    "    densehmm.means_ = mu.reshape(-1, 1)\n",
    "    start = time.perf_counter()\n",
    "    densehmm.fit_coocs(Y_true, lengths)\n",
    "    densehmm.fit(Y_true, lengths)\n",
    "    time_tmp = time.perf_counter() - start\n",
    "\n",
    "#  Results in wanbd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}