{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import  pickle\n",
    "import joblib\n",
    "import optuna\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from eval_utils import *\n",
    "from models_gaussian import GaussianDenseHMM, HMMLoggingMonitor, DenseHMMLoggingMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "t = time.localtime()\n",
    "RESULT_DIR = f'gaussian_dense_hmm_benchmark/eval-cooc-{t.tm_year}-{t.tm_mon}-{t.tm_mday}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have examined the efficiency of co-occurence based learning methods for Gaussian HMM. This notebook contains a comparison of:\n",
    "\n",
    "- standard Gaussian Hidden Markov Model implementation,\n",
    "- co-occurrence based larning for Gaussian Hidden Markov Model,\n",
    "- EM learning for GaussianDenseHHMM,\n",
    "- co-occurrence based learning for GaussianDenseHMM.\n",
    "\n",
    "The dense representation was examined with fixed and tuned embedding length."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "n = 8\n",
    "s = 100\n",
    "T = 100\n",
    "simple_model = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Provide data\n",
    "all_files = os.listdir(RESULT_DIR)\n",
    "\n",
    "results = [s for s in all_files if len(s.split(\"_\")) == 6]\n",
    "studies = [s for s in all_files if len(s.split(\"_\")) == 7]\n",
    "\n",
    "cases = list(set([\"_\".join(s.split(\"_\")[1:-1]) for s in studies]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# read all data\n",
    "experiment = dict(studies  =dict(l_fixed=dict(),  l_tuned=dict()),\n",
    "                  summaries=dict(l_fixed=dict(),  l_tuned=dict()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for c in cases:\n",
    "    with open(f\"{RESULT_DIR}/optuna_{c}_lTrue.pkl\", \"rb\") as f:\n",
    "        experiment[\"studies\"][\"l_fixed\"][c] = joblib.load(f)\n",
    "    with open(f\"{RESULT_DIR}/optuna_{c}_lFalse.pkl\", \"rb\") as f:\n",
    "        experiment[\"studies\"][\"l_tuned\"][c] = joblib.load(f)\n",
    "    with open(f\"{RESULT_DIR}/best_result_{c}_lTrue.json\", \"r\") as f:\n",
    "        experiment[\"summaries\"][\"l_fixed\"][c] = json.load(f)\n",
    "    with open(f\"{RESULT_DIR}/best_result_{c}_lFalse.json\", \"r\") as f:\n",
    "        experiment[\"summaries\"][\"l_tuned\"][c] = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare tunning methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "for c in cases:\n",
    "    display(optuna.visualization.plot_param_importances(experiment[\"studies\"][\"l_fixed\"][c],\n",
    "                                                        target=lambda t: t.values[0], target_name=\"flops\",  title=\"Fixed\"))\n",
    "    display(optuna.visualization.plot_param_importances(experiment[\"studies\"][\"l_tuned\"][c],\n",
    "                                                        target=lambda t: t.values[0], target_name=\"flops\", title=\"Tuned\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# l zafixowane versus wyniki hiperparametryzacji zaleÅ¼nie od l\n",
    "for c in cases:\n",
    "    no_trials = len(experiment[\"studies\"][\"l_fixed\"][c].trials)\n",
    "    x = [experiment[\"studies\"][\"l_fixed\"][c].trials[i].params['l_param'] for i in range(no_trials)]\n",
    "    y = [experiment[\"studies\"][\"l_fixed\"][c].trials[i].values[0] for i in range(no_trials)]\n",
    "    name = cases.split(\"_\")[0]\n",
    "    sns.violinplot(x, y)\n",
    "    plt.xlabel(\"l\")\n",
    "    plt.ylabel(\"log-likelihood\")\n",
    "    plt.title(f\"{name} (when fixed l={int(np.ceil(8 / 3))})\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# s, T, n, simple_model = 100, 40, 4, True\n",
    "#\n",
    "# with open(f\"gaussian_dense_hmm_benchmark/fit_coocs_ll_mini-2022-8-12/optuna_s{s}_T{T}_n{n}_simple_model{simple_model}.pkl\",  \"rb\") as f:\n",
    "#     study = joblib.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare  results of all methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# with open(f\"gaussian_dense_hmm_benchmark/fit_coocs_ll_mini-2022-8-12/best_result_s{s}_T{T}_n{n}_simple_model{simple_model}.json\",  \"r\") as f:\n",
    "#     best_results = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "#  tabularise results\n",
    "for c in cases:\n",
    "    display(f'\\n\\n### {\" \".join(c.split(\"_\"))}')\n",
    "    display(pd.DataFrame(experiment[\"summaries\"][\"l_fixed\"][c]).style.set_caption(\"l fixed\"))\n",
    "    display(pd.DataFrame(experiment[\"summaries\"][\"l_tuned\"][c]).style.set_caption(\"l tuned\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train co-oc + EM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Use the same parameters and provide time benchmarks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s, T, n, pi, A, mu, sigma, result, true_values, wandb_params, X_true, Y_true, lengths, data, em_scheduler = init_experiment(dsize=(100, 100, 8), simple_model=True)\n",
    "\n",
    "\n",
    "def to_discrete(X, m):\n",
    "    kmeans = KMeans(n_clusters=m, random_state=0).fit(Y_true)\n",
    "    nodes_tmp = np.sort(kmeans.cluster_centers_, axis=0)\n",
    "    nodes = np.concatenate([(nodes_tmp[1:] + nodes_tmp[:-1]) / 2, np.array([[np.infty]])])\n",
    "    return (X > nodes.reshape(1, -1)).sum(axis=-1).reshape(-1, 1), nodes.reshape(-1)\n",
    "\n",
    "\n",
    "Y_disc, nodes = to_discrete(Y_true, m=n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for  _  in range(10):\n",
    "    # TODO: read parameters from dense cooc and dense em\n",
    "    cooc_params = experiment[\"studies\"][\"l_fixed\"][c].best_params  # TODO: c\n",
    "    em_params   = experiment[\"studies\"][\"l_fixed\"][c].best_params  # TODO: c\n",
    "    mstep_cofig = {\"cooc_lr\": cooc_params['cooc_lr_param'],\n",
    "                   \"cooc_epochs\": cooc_params['cooc_epochs_param'],\n",
    "                   \"l_uz\": cooc_params['l_param'],\n",
    "                   \"em_params\":  em_params['cooc_lr_param'],\n",
    "                   \"em_epochs\": em_params['cooc_epochs_param'],\n",
    "                   \"loss_type\": 'square',\n",
    "                   \"scheduler\": em_scheduler}\n",
    "    wandb_params[\"init\"].update({\"name\": f\"dense-cooc+em\"})\n",
    "    hmm_monitor = HMMLoggingMonitor(tol=TOLERANCE, n_iter=0, verbose=True,\n",
    "                                    wandb_log=True, wandb_params=wandb_params, true_vals=true_values,\n",
    "                                    log_config={'metrics_after_convergence': True})\n",
    "    densehmm = GaussianDenseHMM(n, mstep_config=mstep_cofig,\n",
    "                                covariance_type='diag', opt_schemes={\"cooc\"},\n",
    "                                nodes=np.concatenate([np.array([-np.infty]), nodes]),\n",
    "                                discrete_observables=n, em_iter=20,\n",
    "                                logging_monitor=hmm_monitor,\n",
    "                                init_params=\"\", params=\"stmc\", early_stopping=True)\n",
    "    densehmm.means_ = mu.reshape(-1, 1)\n",
    "    start = time.perf_counter()\n",
    "    densehmm.fit_coocs(Y_true, lengths)\n",
    "    densehmm.fit(Y_true, lengths)\n",
    "    time_tmp = time.perf_counter() - start\n",
    "\n",
    "#  Results in wanbd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}