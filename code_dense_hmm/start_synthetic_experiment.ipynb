{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "ROOT_PATH = None # Insert the PATH to the directory of this notebook here\n",
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "if ROOT_PATH is None:\n",
    "    raise Exception(\"Please specify the ROOT_PATH\")\n",
    "\n",
    "import experiment\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import imp\n",
    "experiment = imp.reload(experiment)\n",
    "run_experiment = experiment.run_experiment\n",
    "\n",
    "exp_prefix = 'synthetic'\n",
    "\n",
    "nl_dict = {3: [1, 2, 3], 5: [2, 3, 5], 10: [2, 3, 5, 10]}\n",
    "n_seqs = 10\n",
    "seqlen = 200\n",
    "em_lr = 0.01\n",
    "n_gt_iter = 10\n",
    "gt_seqs = dict()\n",
    "\n",
    "experiment_directories = dict()\n",
    "failed_exps = []\n",
    "        \n",
    "for n_hidden_states in nl_dict.keys():\n",
    "\n",
    "    for l in nl_dict[n_hidden_states]:\n",
    "\n",
    "        for i in range(n_gt_iter):\n",
    "            exp_params = {'seqlen_test': seqlen,\n",
    "                          'n_seqs_test': n_seqs, \n",
    "                          'n_seqs_train': n_seqs, \n",
    "                          'seqlen_train': seqlen,\n",
    "                          'n_emissions': n_hidden_states,\n",
    "                          'dirichlet_param': 0.1,\n",
    "                          'standard_params' : {'n_hidden_states': n_hidden_states, \n",
    "                                               'em_iter': 40\n",
    "                                              },\n",
    "                          'standard_log_config': {'gamma_after_estep': False, \n",
    "                                                  'gamma_after_mstep': False, \n",
    "                                                  'samples_after_estep': True, #(n_seqs, seqlen), \n",
    "                                                  'samples_after_mstep': True, #(n_seqs, seqlen)},\n",
    "                                                 },\n",
    "                          'dense_params': {'verbose': False, \n",
    "                                           'em_iter': 40,\n",
    "                                           'n_hidden_states': n_hidden_states, \n",
    "                                           'mstep_config': {'l_uz': l, \n",
    "                                                            'l_vw': l, \n",
    "                                                            'scaling': l*n_hidden_states*n_hidden_states*seqlen*n_seqs,\n",
    "                                                            'trainables': 'uvwzz0',\n",
    "                                                            'em_lr': em_lr,\n",
    "                                                            'initializer': tf.initializers.random_normal(0., 1.),\n",
    "                                                            'em_optimizer': tf.train.AdamOptimizer(em_lr),\n",
    "                                                            'em_epochs': 25,\n",
    "                                                            'cooc_epochs': 10000,\n",
    "                                                            'cooc_optimizer': tf.train.AdamOptimizer(0.001),\n",
    "                                                           }\n",
    "                                          },\n",
    "                          'dense_log_config': {'gamma_after_estep': False, \n",
    "                                               'gamma_after_mstep': False, \n",
    "                                               'samples_after_estep': True, \n",
    "                                               'samples_after_mstep': True,\n",
    "                                              },\n",
    "                          'dense_opt_schemes': ('em','cooc'),\n",
    "                          'gt_params': {'n_hidden_states': n_hidden_states, 'em_iter': 40},\n",
    "                          'gt_samples': (n_seqs, seqlen),\n",
    "                          'gt_stationary': True,\n",
    "                         'compare_to_fair_standard': True,\n",
    "                         'fair_standard_log_config': {'gamma_after_estep': False, \n",
    "                                                      'gamma_after_mstep': False, \n",
    "                                                      'samples_after_estep': True,\n",
    "                                                      'samples_after_mstep': True, \n",
    "                                                     }\n",
    "                         }\n",
    "            try:\n",
    "                directory = run_experiment('synthetic_sequences', '%s/n=m=%d_l=%d_nseqs=%d_seqlen=%d_i=%d_stationary_' % (exp_prefix, n_hidden_states, l, n_seqs, seqlen, i),\n",
    "                           exp_params)\n",
    "                experiment_directories[(i, n_hidden_states, l)] = directory\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                failed_exps.append((i, n_hidden_states, l))\n",
    "                    \n",
    "np.save('%s%s/experiment_directories' % (ROOT_PATH, exp_prefix), experiment_directories)                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf-2-gpu] *",
   "language": "python",
   "name": "conda-env-.conda-tf-2-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
