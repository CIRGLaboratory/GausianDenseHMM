{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrix(n, dirichlet_param=0.1):\n",
    "    alpha = [dirichlet_param for _ in range(n)]\n",
    "    return np.array([np.random.dirichlet(alpha) for _ in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_dict = {3: [1, 2, 3, 5], 5: [1, 3, 5, 10], 10: [1, 5, 10, 15]}\n",
    "\n",
    "# Input params\n",
    "mean = 0.\n",
    "std = 1.\n",
    "lr = 0.01\n",
    "iter_ = 20 # Number of repeatitions per GT matrix and per n,l-parameter\n",
    "n_gt = 10  # Number of GT matrices to generate\n",
    "\n",
    "n_iter = 30000 # Optimization iterations\n",
    "min_iter = 2000 # Minimum number of optimization iteration\n",
    "convergence_tol = 0. # Convergence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "def build_graph(n, l):\n",
    "    \n",
    "    A_gt = tf.placeholder(dtype=tf.float32, shape=[n, n])\n",
    "    init_normal = tf.random_normal_initializer(mean, stddev=std)\n",
    "    \n",
    "    # Approach (i) - normAbsLin factorization with normalization\n",
    "    with tf.variable_scope(\"%d%d_lin\" % (n, l), reuse=tf.AUTO_REUSE):\n",
    "        V_lin = tf.get_variable(\"V\", shape=[n, l], dtype=tf.float32, initializer=init_normal)\n",
    "        W_lin = tf.get_variable(\"W\", shape=[l, n], dtype=tf.float32, initializer=init_normal)\n",
    "    \n",
    "    A_tilde_lin = tf.math.abs(tf.matmul(V_lin, W_lin))\n",
    "    A_tilde_lin /= tf.reduce_sum(A_tilde_lin, axis=1)[:, None]\n",
    "    A_sum_lin = tf.reduce_sum(A_tilde_lin, axis=1)\n",
    "    loss_lin = tf.norm(A_gt - A_tilde_lin)\n",
    "    loss_norm_lin = tf.norm(A_gt - A_tilde_lin) / tf.norm(A_gt)\n",
    "    #opt_lin = tf.train.GradientDescentOptimizer(lr).minimize(loss_norm_lin)\n",
    "    \n",
    "    with tf.variable_scope(\"%d%d_lin\" % (n, l), reuse=tf.AUTO_REUSE):\n",
    "        opt_lin = tf.train.AdamOptimizer(lr).minimize(loss_norm_lin)\n",
    "    \n",
    "    # Approach (ii) - Softmax factorization\n",
    "    with tf.variable_scope(\"%d%d_sm\" % (n, l), reuse=tf.AUTO_REUSE):\n",
    "        V_sm = tf.Variable(V_lin.initialized_value(), dtype=tf.float32, name=\"V\")#tf.get_variable(\"V\", shape=[n, l], dtype=tf.float32, initializer=init_normal)\n",
    "        W_sm = tf.Variable(W_lin.initialized_value(), dtype=tf.float32, name=\"W\")\n",
    "\n",
    "    A_tilde_sm = tf.math.softmax(tf.matmul(V_sm, W_sm))\n",
    "    A_sum_sm = tf.reduce_sum(A_tilde_sm, axis=1)\n",
    "    loss_sm = tf.norm(A_gt - A_tilde_sm)\n",
    "    loss_norm_sm = tf.norm(A_gt - A_tilde_sm) / tf.norm(A_gt)\n",
    "    #opt_sm = tf.train.GradientDescentOptimizer(lr).minimize(loss_norm_sm)\n",
    "    \n",
    "    with tf.variable_scope(\"%d%d_sm\" % (n, l), reuse=tf.AUTO_REUSE):\n",
    "        opt_sm = tf.train.AdamOptimizer(lr).minimize(loss_norm_sm)\n",
    "    \n",
    "    #opt = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    return init, A_gt, A_tilde_lin, A_tilde_sm, opt_lin, opt_sm, loss_norm_lin, loss_norm_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_dir = 'matrix_fit_exp_adam' + datetime.now().strftime('%Y%m%d_%H-%M-%S')\n",
    "os.mkdir('./%s' % exp_dir)\n",
    "os.mkdir('./%s/savepoints' % exp_dir) \n",
    "\n",
    "gt_mats = dict()\n",
    "losses_sm, losses_relu, losses_lin = dict(), dict(), dict()\n",
    "mean_losses_sm, mean_losses_relu, mean_losses_lin = dict(), dict(), dict()\n",
    "std_losses_sm, std_losses_relu, std_losses_lin = dict(), dict(), dict()\n",
    "optimized_mat_sm, optimized_mat_relu, optimized_mat_lin = dict(), dict(), dict()\n",
    "init_loss_sm, init_loss_relu, init_loss_lin = dict(), dict(), dict()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "for i in range(n_gt):  # Do the training for n_gt matrices\n",
    "\n",
    "    for n, l_list in nl_dict.iteritems():\n",
    "        \n",
    "        _A_inp = generate_matrix(n)\n",
    "        gt_mats[(i, n)] = _A_inp\n",
    "\n",
    "        for l in l_list:\n",
    "\n",
    "            losses_sm[(i, n, l)], losses_lin[(i, n, l)] = [], []\n",
    "            optimized_mat_sm[(i, n, l)], optimized_mat_lin[(i, n, l)] = [], []\n",
    "            init_loss_sm[(i, n, l)], init_loss_lin[(i, n, l)] = [], []\n",
    "            \n",
    "            init, A, A_tilde_lin, A_tilde_sm, opt_lin, opt_sm, loss_norm_lin, loss_norm_sm = build_graph(n, l)\n",
    "            feed_dict_ = {A: _A_inp}\n",
    "            print(\"build graph\", i, n, l)\n",
    "            \n",
    "            prev_loss_lin, prev_loss_sm = 0., 0.\n",
    "\n",
    "            for _ in range(iter_):\n",
    "\n",
    "                sess.run(init)  # Re-initialize variables (re-draws U, V)\n",
    "                prev_loss_lin = sess.run([loss_norm_lin], feed_dict=feed_dict_)\n",
    "                prev_loss_sm = sess.run([loss_norm_sm], feed_dict_)\n",
    "                \n",
    "                init_loss_lin[(i, n, l)].append(prev_loss_lin)\n",
    "                init_loss_sm[(i, n, l)].append(prev_loss_sm)\n",
    "\n",
    "                for step in range(n_iter):\n",
    "                    \n",
    "                    if step < min_iter:\n",
    "                        _, _ = sess.run([opt_lin, opt_sm], feed_dict=feed_dict_)\n",
    "                    else:\n",
    "                        opt = []\n",
    "                        if not ((cur_loss_lin <= prev_loss_lin) and (prev_loss_lin - cur_loss_lin <= convergence_tol)):\n",
    "                            opt.append(opt_lin)\n",
    "                        if not ((cur_loss_sm <= prev_loss_sm) and (prev_loss_sm - cur_loss_sm <= convergence_tol)):\n",
    "                            opt.append(opt_sm)\n",
    "                        \n",
    "                        if len(opt) < 1:  # All converged\n",
    "                            print(\"All converged\")\n",
    "                            break\n",
    "                        else:\n",
    "                            sess.run(opt, feed_dict=feed_dict_)\n",
    "                        \n",
    "                    if step >= 2:\n",
    "                        prev_loss_lin, prev_loss_sm = cur_loss_lin, cur_loss_sm\n",
    "                    cur_loss_lin, cur_loss_sm = sess.run([loss_norm_lin, loss_norm_sm], feed_dict=feed_dict_)\n",
    "\n",
    "                    if step % 5000 == 0:\n",
    "                        print(cur_loss_lin, cur_loss_sm)\n",
    "\n",
    "                optimized_mat_lin[(i, n, l)].append(sess.run([A_tilde_lin]))\n",
    "                optimized_mat_sm[(i, n, l)].append(sess.run([A_tilde_sm]))\n",
    "\n",
    "                print(i, n, l, cur_loss_lin, cur_loss_sm)\n",
    "                losses_lin[(i, n, l)].append(cur_loss_lin)\n",
    "                losses_sm[(i, n, l)].append(cur_loss_sm)\n",
    "\n",
    "            mean_losses_sm[(i, n, l)], mean_losses_lin[(i, n, l)] = np.mean(losses_sm[(i, n, l)]), np.mean(losses_lin[(i, n, l)])\n",
    "            std_losses_sm[(i, n, l)], std_losses_lin[(i, n, l)] = np.std(losses_sm[(i, n, l)]), np.std(losses_lin[(i, n, l)])\n",
    "        \n",
    "    np.save('%s/savepoints/losses_lin.npy' % exp_dir, losses_lin)\n",
    "    np.save('%s/savepoints/losses_sm.npy'% exp_dir, losses_sm)\n",
    "    np.save('%s/savepoints/mean_losses_lin.npy'% exp_dir, mean_losses_lin)\n",
    "    np.save('%s/savepoints/mean_losses_sm.npy'% exp_dir, mean_losses_sm)\n",
    "    np.save('%s/savepoints/std_losses_sm.npy'% exp_dir, std_losses_sm)\n",
    "    np.save('%s/savepoints/std_losses_lin.npy'% exp_dir, std_losses_lin)\n",
    "    np.save('%s/savepoints/optimized_mat_lin.npy'% exp_dir, optimized_mat_lin)\n",
    "    np.save('%s/savepoints/optimized_mat_sm.npy'% exp_dir, optimized_mat_sm)\n",
    "    np.save('%s/savepoints/init_loss_sm.npy'% exp_dir, init_loss_sm)\n",
    "    np.save('%s/savepoints/init_loss_lin.npy'% exp_dir, init_loss_lin)\n",
    "    np.save('%s/savepoints/gt_mats.npy'% exp_dir,gt_mats)\n",
    "        \n",
    "        \n",
    "np.save('%s/losses_lin.npy' % exp_dir, losses_lin)\n",
    "np.save('%s/losses_sm.npy'% exp_dir, losses_sm)\n",
    "                   \n",
    "np.save('%s/mean_losses_lin.npy'% exp_dir, mean_losses_lin)\n",
    "np.save('%s/mean_losses_sm.npy'% exp_dir, mean_losses_sm)\n",
    "                   \n",
    "np.save('%s/std_losses_sm.npy'% exp_dir, std_losses_sm)\n",
    "np.save('%s/std_losses_lin.npy'% exp_dir, std_losses_lin)\n",
    "                   \n",
    "np.save('%s/optimized_mat_lin.npy'% exp_dir, optimized_mat_lin)\n",
    "np.save('%s/optimized_mat_sm.npy'% exp_dir, optimized_mat_sm)\n",
    "                   \n",
    "np.save('%s/init_loss_sm.npy'% exp_dir, init_loss_sm)\n",
    "np.save('%s/init_loss_lin.npy'% exp_dir, init_loss_lin)\n",
    "\n",
    "np.save('%s/gt_mats.npy'% exp_dir,gt_mats)\n",
    "                   \n",
    "print(\"Done\")\n",
    "print(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tf-2-gpu] *",
   "language": "python",
   "name": "conda-env-.conda-tf-2-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
